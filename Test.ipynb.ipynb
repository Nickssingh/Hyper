{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparamter Tuning - XGBoost\n",
    "\n",
    "# Here is the highlight of the process\n",
    "# 1. Import the customer churn data (I have already cleaned it)\n",
    "# 2. Split the data into test and train sets\n",
    "# 3. Build data matrices - as XGBoost uses DMatrix\n",
    "# 4. Find the logloss of the model with default parameters\n",
    "# 5. Tune the parameters\n",
    "# 6. Find the logloss of the model with tuned parameters\n",
    "\n",
    "# For exploratory analysis and other models on this dataset, please use the following link\n",
    "# https://github.com/Nickssingh/Churn-Prediction-Model-Telecommunication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will import the dataset and view top rows\n",
    "# I have already preapared the the data for analysis \n",
    "    # Removed the missing values\n",
    "    # Converted the variables into appropriate data types\n",
    "    # Encoded categorical variables using one hot encoding\n",
    "\n",
    "df_churn=pd.read_csv(\"https://github.com/Nickssingh/Hyperparameter-tuning-XGBoost/raw/master/Data/telcom_customer_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No phone service</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingTV_No internet service</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_No internet service</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  TotalCharges  Churn  gender_Male  \\\n",
       "0              0       1           29.85         29.85      0            0   \n",
       "1              0      34           56.95       1889.50      0            1   \n",
       "2              0       2           53.85        108.15      1            1   \n",
       "3              0      45           42.30       1840.75      0            1   \n",
       "4              0       2           70.70        151.65      1            0   \n",
       "\n",
       "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
       "0            1               0                 0   \n",
       "1            0               0                 1   \n",
       "2            0               0                 1   \n",
       "3            0               0                 0   \n",
       "4            0               0                 1   \n",
       "\n",
       "   MultipleLines_No phone service             ...              \\\n",
       "0                               1             ...               \n",
       "1                               0             ...               \n",
       "2                               0             ...               \n",
       "3                               1             ...               \n",
       "4                               0             ...               \n",
       "\n",
       "   StreamingTV_No internet service  StreamingTV_Yes  \\\n",
       "0                                0                0   \n",
       "1                                0                0   \n",
       "2                                0                0   \n",
       "3                                0                0   \n",
       "4                                0                0   \n",
       "\n",
       "   StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
       "0                  0                  0                     1   \n",
       "1                  1                  0                     0   \n",
       "2                  0                  0                     1   \n",
       "3                  1                  0                     0   \n",
       "4                  0                  0                     1   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dimension of the data\n",
    "\n",
    "df_churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test datasets\n",
    "# test:train = 3:7\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "df_temp = df_churn\n",
    "y = df_temp['Churn']\n",
    "X = df_temp.drop('Churn', axis=1, inplace=False)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: xgboost in ./anaconda2/lib/python2.7/site-packages (0.82)\n",
      "Requirement already satisfied: numpy in ./anaconda2/lib/python2.7/site-packages (from xgboost) (1.11.1)\n",
      "Requirement already satisfied: scipy in ./anaconda2/lib/python2.7/site-packages (from xgboost) (0.17.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing XGBoost (I have already installed it)\n",
    "\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost uses an internal data structure DMatrix - which optimizes both memory effieciency and speed\n",
    "# Hence, rather than using pandas dataframe, we will use data matrix - DMatrix\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dm_train = xgb.DMatrix(X_train, label=y_train)\n",
    "dm_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building Model\n",
    "\n",
    "# Ideal case would include an exhaustive gridsearch on all the parameters.\n",
    "# However, such an approach is computationally intensive.\n",
    "# Hence, we will focus on few important parameters and tune them sequentially.\n",
    "\n",
    "# Following are the parameters that we will tune in this process\n",
    "# max_depth\n",
    "# min_child_weight\n",
    "# subsample\n",
    "# colsample_bytree\n",
    "# eta\n",
    "# num_boost_rounds\n",
    "# early_stopping_rounds\n",
    "\n",
    "# We will use logistic loss function to assess the accuracy of predictions, as this is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.581809\n",
      "Will train until Test-logloss hasn't improved in 10 rounds.\n",
      "[1]\tTest-logloss:0.520662\n",
      "[2]\tTest-logloss:0.484648\n",
      "[3]\tTest-logloss:0.459301\n",
      "[4]\tTest-logloss:0.44479\n",
      "[5]\tTest-logloss:0.43489\n",
      "[6]\tTest-logloss:0.428768\n",
      "[7]\tTest-logloss:0.427162\n",
      "[8]\tTest-logloss:0.425635\n",
      "[9]\tTest-logloss:0.423885\n",
      "[10]\tTest-logloss:0.424516\n",
      "[11]\tTest-logloss:0.425703\n",
      "[12]\tTest-logloss:0.426199\n",
      "[13]\tTest-logloss:0.426466\n",
      "[14]\tTest-logloss:0.427974\n",
      "[15]\tTest-logloss:0.428433\n",
      "[16]\tTest-logloss:0.429665\n",
      "[17]\tTest-logloss:0.429645\n",
      "[18]\tTest-logloss:0.42989\n",
      "[19]\tTest-logloss:0.430252\n",
      "Stopping. Best iteration:\n",
      "[9]\tTest-logloss:0.423885\n",
      "\n",
      "Best Logloss: 0.424 | Rounds: 10\n"
     ]
    }
   ],
   "source": [
    "# We will set num_boost_rounds to 100, early_stopping_rounds to 10, and objective to binary:logistic.\n",
    "# All the other values at this stage are default values.\n",
    "# We will tune our model by chaning the default values.\n",
    "\n",
    "params = {'max_depth':6, 'min_child_weight':1, 'eta':0.3, 'subsample':1, \n",
    "          'colsample_bytree':1, 'objective':'binary:logistic',}\n",
    "\n",
    "# We will use logloss function to evaluate the model's performance\n",
    "params['eval_metric'] = \"logloss\"\n",
    "\n",
    "xgmodel = xgb.train(params, dtrain = dm_train, num_boost_round = 100, evals = [(dm_test,\"Test\")], \n",
    "                    early_stopping_rounds = 10)\n",
    "\n",
    "print(\"Best Logloss: {:.3f} | Rounds: {}\".format(xgmodel.best_score,xgmodel.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we found that the tenth round gave the best result and the results did not improve in the next 10 rounds\n",
    "# Hence, the iteration stopped at round 19 and we did not reach the maximum number of boosting rounds (100).\n",
    "\n",
    "# Finding a suitable evidence to stop the iterations is important.\n",
    "# Stopping the iterations when results do not improve prevents overfittig and the inefficient utilization of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use cross validation to tune the parameters within the params dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters: max-depth and min_child_weight\n",
    "# I realized that the optimal values are in the following ranges through multiple iterations\n",
    "\n",
    "gridsearch_params = [(max_depth, min_child_weight)\n",
    "                    for max_depth in range(1,4)\n",
    "                    for min_child_weight in range(17,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 | min_child_weight: 17 with Logloss: 0.41\n",
      "\n",
      "max_depth: 1 | min_child_weight: 18 with Logloss: 0.41\n",
      "\n",
      "max_depth: 1 | min_child_weight: 19 with Logloss: 0.41\n",
      "\n",
      "max_depth: 1 | min_child_weight: 20 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 17 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 18 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 19 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 20 with Logloss: 0.41\n",
      "\n",
      "max_depth: 3 | min_child_weight: 17 with Logloss: 0.412\n",
      "\n",
      "max_depth: 3 | min_child_weight: 18 with Logloss: 0.413\n",
      "\n",
      "max_depth: 3 | min_child_weight: 19 with Logloss: 0.413\n",
      "\n",
      "max_depth: 3 | min_child_weight: 20 with Logloss: 0.414\n",
      "\n",
      "Best Parameters: max_depth: 2 | min_child_weight: 19 with Logloss: 0.410\n"
     ]
    }
   ],
   "source": [
    "logloss_min = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    \n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    xg_cvresults = xgb.cv(params, dtrain = dm_train, num_boost_round = 100,\n",
    "                      seed = 0, nfold=10, metrics = {'logloss'}, early_stopping_rounds = 10,)\n",
    "    \n",
    "    logloss_mean = xg_cvresults['test-logloss-mean'].min()\n",
    "    \n",
    "    print(\"max_depth: {} | min_child_weight: {} with Logloss: {:.3}\\n\".format(max_depth,min_child_weight,logloss_mean))\n",
    "    \n",
    "    if logloss_mean < logloss_min:\n",
    "        logloss_min = logloss_mean\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "\n",
    "        \n",
    "print(\"Best Parameters: max_depth: {} | min_child_weight: {} with Logloss: {:.3f}\". format(best_params[0], \n",
    "                                                                                  best_params[1], logloss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the parameters with the best values: max_depth = 2 and min_child_weight = 19\n",
    "\n",
    "params['max_depth'] = 2\n",
    "params['min_child_weight'] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters: subsample and colsample_bytree\n",
    "# I found that the optimal values are in the following ranges through multiple iterations\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(1,5)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.7 | colsample: 0.1 with Logloss: 0.412\n",
      "\n",
      "subsample: 0.7 | colsample: 0.2 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.7 | colsample: 0.3 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.7 | colsample: 0.4 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.8 | colsample: 0.1 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.8 | colsample: 0.2 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.8 | colsample: 0.3 with Logloss: 0.409\n",
      "\n",
      "subsample: 0.8 | colsample: 0.4 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.1 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.2 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.3 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.4 with Logloss: 0.409\n",
      "\n",
      "subsample: 1.0 | colsample: 0.1 with Logloss: 0.410\n",
      "\n",
      "subsample: 1.0 | colsample: 0.2 with Logloss: 0.411\n",
      "\n",
      "subsample: 1.0 | colsample: 0.3 with Logloss: 0.410\n",
      "\n",
      "subsample: 1.0 | colsample: 0.4 with Logloss: 0.410\n",
      "\n",
      "Best Parameters: subsample: 0.9 | colsample: 0.4 with Logloss: 0.409\n"
     ]
    }
   ],
   "source": [
    "logloss_min = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in (gridsearch_params):\n",
    "    \n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    \n",
    "    xg_cvresults = xgb.cv(params, dtrain = dm_train, num_boost_round = 100,\n",
    "                      seed = 0, nfold=10, metrics = {'logloss'}, early_stopping_rounds = 10,)\n",
    "    \n",
    "    logloss_mean = xg_cvresults['test-logloss-mean'].min()\n",
    "    \n",
    "    print(\"subsample: {} | colsample: {} with Logloss: {:.3f}\\n\".format(subsample,colsample,logloss_mean))\n",
    "    \n",
    "    if logloss_mean < logloss_min:\n",
    "        logloss_min = logloss_mean\n",
    "        best_params = (subsample, colsample)\n",
    "        \n",
    "print(\"Best Parameters: subsample: {} | colsample: {} with Logloss: {:.3f}\". format(best_params[0], \n",
    "                                                                           best_params[1], logloss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the parameters with the best values: subsample = 0.9 and colsample = 0.2\n",
    "\n",
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta: 0.3 with Logloss: 0.41\n",
      "\n",
      "eta: 0.2 with Logloss: 0.409\n",
      "\n",
      "eta: 0.1 with Logloss: 0.411\n",
      "\n",
      "eta: 0.05 with Logloss: 0.423\n",
      "\n",
      "eta: 0.01 with Logloss: 0.525\n",
      "\n",
      "eta: 0.005 with Logloss: 0.582\n",
      "\n",
      "Best Parameter: eta: 0.2 with Logloss: 0.409\n"
     ]
    }
   ],
   "source": [
    "# Parameter: eta\n",
    "\n",
    "logloss_min = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [0.3, 0.2, 0.1, 0.05, 0.01, 0.005]:\n",
    "    \n",
    "    params['eta'] = eta\n",
    "    \n",
    "    xg_cvresults = xgb.cv(params, dtrain = dm_train, num_boost_round = 100,\n",
    "                      seed = 0, nfold=10, metrics = {'logloss'}, early_stopping_rounds = 10,)\n",
    "    \n",
    "    logloss_mean = xg_cvresults['test-logloss-mean'].min()\n",
    "    print(\"eta: {} with Logloss: {:.3}\\n\".format(eta,logloss_mean))\n",
    "    \n",
    "    if logloss_mean < logloss_min:\n",
    "        logloss_min = logloss_mean\n",
    "        best_params = eta\n",
    "        \n",
    "print(\"Best Parameter: eta: {} with Logloss: {:.3f}\". format(best_params, logloss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the eta parameter with the best value\n",
    "\n",
    "params['eta'] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the optimum paramters\n",
    "\n",
    "params = {'colsample_bytree': 0.2,\n",
    "          'eta': 0.2,\n",
    "          'eval_metric': 'logloss',\n",
    "          'max_depth': 2,\n",
    "          'min_child_weight': 19,\n",
    "          'objective':'binary:logistic',\n",
    "          'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.635076\n",
      "Will train until Test-logloss hasn't improved in 10 rounds.\n",
      "[1]\tTest-logloss:0.587516\n",
      "[2]\tTest-logloss:0.559388\n",
      "[3]\tTest-logloss:0.532871\n",
      "[4]\tTest-logloss:0.511868\n",
      "[5]\tTest-logloss:0.499512\n",
      "[6]\tTest-logloss:0.485791\n",
      "[7]\tTest-logloss:0.476895\n",
      "[8]\tTest-logloss:0.469163\n",
      "[9]\tTest-logloss:0.45966\n",
      "[10]\tTest-logloss:0.455054\n",
      "[11]\tTest-logloss:0.452829\n",
      "[12]\tTest-logloss:0.4477\n",
      "[13]\tTest-logloss:0.444522\n",
      "[14]\tTest-logloss:0.438465\n",
      "[15]\tTest-logloss:0.435882\n",
      "[16]\tTest-logloss:0.434745\n",
      "[17]\tTest-logloss:0.433169\n",
      "[18]\tTest-logloss:0.431758\n",
      "[19]\tTest-logloss:0.430851\n",
      "[20]\tTest-logloss:0.428035\n",
      "[21]\tTest-logloss:0.427202\n",
      "[22]\tTest-logloss:0.426541\n",
      "[23]\tTest-logloss:0.426402\n",
      "[24]\tTest-logloss:0.425321\n",
      "[25]\tTest-logloss:0.423764\n",
      "[26]\tTest-logloss:0.423377\n",
      "[27]\tTest-logloss:0.423043\n",
      "[28]\tTest-logloss:0.422699\n",
      "[29]\tTest-logloss:0.422123\n",
      "[30]\tTest-logloss:0.422191\n",
      "[31]\tTest-logloss:0.422346\n",
      "[32]\tTest-logloss:0.422648\n",
      "[33]\tTest-logloss:0.422762\n",
      "[34]\tTest-logloss:0.42282\n",
      "[35]\tTest-logloss:0.422688\n",
      "[36]\tTest-logloss:0.421593\n",
      "[37]\tTest-logloss:0.420451\n",
      "[38]\tTest-logloss:0.420149\n",
      "[39]\tTest-logloss:0.419774\n",
      "[40]\tTest-logloss:0.419875\n",
      "[41]\tTest-logloss:0.419383\n",
      "[42]\tTest-logloss:0.419505\n",
      "[43]\tTest-logloss:0.419253\n",
      "[44]\tTest-logloss:0.418922\n",
      "[45]\tTest-logloss:0.418736\n",
      "[46]\tTest-logloss:0.418558\n",
      "[47]\tTest-logloss:0.418375\n",
      "[48]\tTest-logloss:0.418318\n",
      "[49]\tTest-logloss:0.418191\n",
      "[50]\tTest-logloss:0.418153\n",
      "[51]\tTest-logloss:0.417865\n",
      "[52]\tTest-logloss:0.417786\n",
      "[53]\tTest-logloss:0.417777\n",
      "[54]\tTest-logloss:0.41771\n",
      "[55]\tTest-logloss:0.417762\n",
      "[56]\tTest-logloss:0.417707\n",
      "[57]\tTest-logloss:0.4176\n",
      "[58]\tTest-logloss:0.417542\n",
      "[59]\tTest-logloss:0.4173\n",
      "[60]\tTest-logloss:0.417175\n",
      "[61]\tTest-logloss:0.417275\n",
      "[62]\tTest-logloss:0.417174\n",
      "[63]\tTest-logloss:0.417044\n",
      "[64]\tTest-logloss:0.41696\n",
      "[65]\tTest-logloss:0.416962\n",
      "[66]\tTest-logloss:0.417013\n",
      "[67]\tTest-logloss:0.416974\n",
      "[68]\tTest-logloss:0.416741\n",
      "[69]\tTest-logloss:0.416781\n",
      "[70]\tTest-logloss:0.416985\n",
      "[71]\tTest-logloss:0.416962\n",
      "[72]\tTest-logloss:0.416972\n",
      "[73]\tTest-logloss:0.416763\n",
      "[74]\tTest-logloss:0.416882\n",
      "[75]\tTest-logloss:0.416991\n",
      "[76]\tTest-logloss:0.41697\n",
      "[77]\tTest-logloss:0.416907\n",
      "[78]\tTest-logloss:0.417004\n",
      "Stopping. Best iteration:\n",
      "[68]\tTest-logloss:0.416741\n",
      "\n",
      "Best Logloss: 0.417 in 69 rounds\n"
     ]
    }
   ],
   "source": [
    "# Finding the optimal number of rounds for the model with new parameters\n",
    "\n",
    "xgmodel_tuned = xgb.train(params, dtrain = dm_train, \n",
    "                          num_boost_round=100, evals=[(dm_test,\"Test\")], early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "print(\"Best Logloss: {:.3f} in {} rounds\". format(xgmodel_tuned.best_score, xgmodel_tuned.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With the tuned parameters we would need 63 rounds to achieve the best result\n",
    "\n",
    "# The improvement after parameter tuning is marginal in our case.\n",
    "    # Logloss of our model decreased from 0.424 to 0.417\n",
    "# However, we were able to see how parameters can be tuned.\n",
    "\n",
    "# Here we have used only a few combination of parameters.\n",
    "# We can further improve the impact of tuning; however, doing so would be computationally more expensive.\n",
    "# More combination of parameters and wider ranges of values for each of those paramaters would have to be tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
